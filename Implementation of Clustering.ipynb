{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()\n",
    "iris_df = pandas.DataFrame(iris.data)\n",
    "iris_df.columns = iris.feature_names\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "My DBSCAN 0.6476102752155394\n",
      "Scikit Learn DBSCAN 0.5058120433673868\n"
     ]
    }
   ],
   "source": [
    "def distance_squared(x1,x2):\n",
    "    squared_distance = 0\n",
    "    for k in range(len(x1)):\n",
    "        squared_distance += (x1[k] - x2[k])**2\n",
    "    return squared_distance\n",
    "class DBScan:\n",
    "    def __init__(self, eps, min_sample, data):\n",
    "        self.eps = eps\n",
    "        self.min_sample = min_sample\n",
    "        self.data = data\n",
    "    def neighbors(self):\n",
    "        #Lists are for quick implementation, probably should've used objects/classes\n",
    "        self.neighbors_list = (list([] for i in range(len(self.data))))\n",
    "        self.core_list = (list([] for i in range(len(self.data))))\n",
    "        self.new_cores = (list([] for i in range(len(self.data))))\n",
    "        self.label = list(\"\" for i in range(len(self.data)))\n",
    "        #The first for loop gets data points from the dataset and compares the distance \n",
    "        #between the values to determine if the point are lower than eps\n",
    "        for x in range(0,len(self.data)):\n",
    "            for y in range(x + 1, len(self.data)):\n",
    "                rows = self.data.iloc[[x,y]]\n",
    "                if distance_squared(rows.values[0], rows.values[1]) < self.eps**2:\n",
    "                    self.neighbors_list[x].append(y)\n",
    "                    self.neighbors_list[y].append(x)\n",
    "        #neighbors_count = map(lambda x: len(x), self.neighbors_list)\n",
    "        #Goes through all the unlabeled points and gives them a new label or labels them as \"noise\"\n",
    "        for point in range(0, len(self.data)):\n",
    "            cluster_label = point\n",
    "            if (self.label[point] == \"\"):\n",
    "                if len(self.neighbors_list[point]) < self.min_sample:\n",
    "                    self.label[point] = \"noise\"\n",
    "                else:\n",
    "                    self.label[point] = cluster_label\n",
    "                    #Once a point is given a new label, it'll give all its neighbors a new label\n",
    "                    for neighbor in self.neighbors_list[point]:\n",
    "                        if (self.label[neighbor] == \"\" or self.label[neighbor] == \"noise\"):\n",
    "                            self.label[neighbor] = cluster_label\n",
    "                            #Core points are placed into another list and they go through a similar process\n",
    "                            if len(self.neighbors_list[neighbor]) > self.min_sample:\n",
    "                                self.core_list[point].append(neighbor)\n",
    "                                self.new_cores[point].append(neighbor)\n",
    "                    self.core_loop(point, cluster_label)\n",
    "        print(self.core_list)\n",
    "        print(self.label)\n",
    "    def core_loop(self, index, cluster_label):\n",
    "        #more stupid for loop stuff\n",
    "        #the core_list is to make sure points aren't iterated over again\n",
    "        temp_new_cores = []\n",
    "        for point in self.core_list[index]:\n",
    "            for neighbor in self.neighbors_list[point]:\n",
    "                if (self.label[neighbor] == \"\" or self.label[neighbor] == \"noise\"):\n",
    "                    self.label[neighbor] = cluster_label\n",
    "                    if len(self.neighbors_list[neighbor]) > self.min_sample:\n",
    "                        if (neighbor not in self.core_list[index]):\n",
    "                            self.core_list[index].append(neighbor)\n",
    "                            temp_new_cores.append(neighbor)\n",
    "        if temp_new_cores != []:\n",
    "            #I couldn't figure out a way to avoid recursion, so this implementation would fail \n",
    "            #if there were enough data points to exceed stack limit\n",
    "            self.new_cores[index] = temp_new_cores\n",
    "            self.core_loop(index, cluster_label)\n",
    "        \n",
    "# dbscan = DBScan(0.43, 5, iris_df)\n",
    "# dbscan.neighbors()\n",
    "realModel = DBSCAN(eps = 0.43, min_samples = 5)\n",
    "realModel.fit(iris_df)\n",
    "print(iris.target)\n",
    "print(\"My DBSCAN\", metrics.adjusted_rand_score(iris.target, dbscan.label) )\n",
    "print(\"Scikit Learn DBSCAN\", metrics.adjusted_rand_score(iris.target, realModel.labels_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not quite sure why my DBSCAN would create 3 clusters as opposed to scikit learn's 2 clusters, my model somehow did better. However, I would assume scikit learn's might perform better with different datasets. Plus, even if scikit-learn is worse than my model, it still runs about 100x faster than my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
